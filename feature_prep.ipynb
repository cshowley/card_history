{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23de282",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "872dbf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration constants\n",
    "NUMBER_OF_BIDS_FILTER = 3\n",
    "TOP_N_SELLERS = 5\n",
    "N_SALES_BACK = 5\n",
    "WEEKS_BACK_LIST = [1, 2, 3, 4]\n",
    "MARKET_FILE = \"market.csv\"\n",
    "INDEX_FILE = \"index.csv\"\n",
    "FEATURES_PREPPED_FILE = \"features_prepped.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76c3a2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 384024\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>grading_company</th>\n",
       "      <th>item_data.date</th>\n",
       "      <th>item_data.price</th>\n",
       "      <th>item_data.number_of_bids</th>\n",
       "      <th>item_data.seller_name</th>\n",
       "      <th>item_data.best_offer_accepted</th>\n",
       "      <th>gemrate_data.grade</th>\n",
       "      <th>gemrate_hybrid_data.specid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68ebd6800047dc1fd31fa5d7</td>\n",
       "      <td>PSA</td>\n",
       "      <td>2025-09-19</td>\n",
       "      <td>$114.50</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>g8</td>\n",
       "      <td>10000113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68ebd72d0047dc1fd322e869</td>\n",
       "      <td>PSA</td>\n",
       "      <td>2025-09-28</td>\n",
       "      <td>US $51.00</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>g1_5</td>\n",
       "      <td>10000399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68ebd72d0047dc1fd322e875</td>\n",
       "      <td>PSA</td>\n",
       "      <td>2025-09-28</td>\n",
       "      <td>US $51.00</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>g1_5</td>\n",
       "      <td>10000399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6915f1a06a0ba9a2b33e126e</td>\n",
       "      <td>PSA</td>\n",
       "      <td>2025-11-10</td>\n",
       "      <td>$184.52</td>\n",
       "      <td>21</td>\n",
       "      <td>PSA</td>\n",
       "      <td>False</td>\n",
       "      <td>g9</td>\n",
       "      <td>10000421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>69293bfe6ea7c07da4f98b66</td>\n",
       "      <td>PSA</td>\n",
       "      <td>2025-10-04</td>\n",
       "      <td>US $219.48</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>g9</td>\n",
       "      <td>10000421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id grading_company item_data.date item_data.price  \\\n",
       "0  68ebd6800047dc1fd31fa5d7             PSA     2025-09-19         $114.50   \n",
       "1  68ebd72d0047dc1fd322e869             PSA     2025-09-28       US $51.00   \n",
       "2  68ebd72d0047dc1fd322e875             PSA     2025-09-28       US $51.00   \n",
       "3  6915f1a06a0ba9a2b33e126e             PSA     2025-11-10         $184.52   \n",
       "4  69293bfe6ea7c07da4f98b66             PSA     2025-10-04      US $219.48   \n",
       "\n",
       "   item_data.number_of_bids item_data.seller_name  \\\n",
       "0                        27                   NaN   \n",
       "1                        13                   NaN   \n",
       "2                        15                   NaN   \n",
       "3                        21                   PSA   \n",
       "4                        28                   NaN   \n",
       "\n",
       "   item_data.best_offer_accepted gemrate_data.grade  \\\n",
       "0                          False                 g8   \n",
       "1                          False               g1_5   \n",
       "2                          False               g1_5   \n",
       "3                          False                 g9   \n",
       "4                          False                 g9   \n",
       "\n",
       "   gemrate_hybrid_data.specid  \n",
       "0                    10000113  \n",
       "1                    10000399  \n",
       "2                    10000399  \n",
       "3                    10000421  \n",
       "4                    10000421  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_keep = []\n",
    "df = pd.read_csv(MARKET_FILE)\n",
    "print(f\"Number of samples: {len(df)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "156a4f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min Date: 2025-09-01 00:00:00\n",
      "Max Date: 2025-12-04 00:00:00\n"
     ]
    }
   ],
   "source": [
    "df['date'] = pd.to_datetime(df['item_data.date'], errors='coerce')\n",
    "df.dropna(subset=['date'], inplace=True)\n",
    "print(f\"Min Date: {df['date'].min()}\")\n",
    "print(f\"Max Date: {df['date'].max()}\")\n",
    "columns_to_keep.append('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c071e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows: 384024\n",
      "Number of rows with missing spec_id: 0\n",
      "Number of rows after removing missing spec_id: 384024\n"
     ]
    }
   ],
   "source": [
    "df[\"spec_id\"] = df[\"gemrate_hybrid_data.specid\"].astype(int)\n",
    "print(\"Total number of rows:\", len(df))\n",
    "print(\"Number of rows with missing spec_id:\", df['spec_id'].isna().sum())\n",
    "df = df.dropna(subset=['spec_id'])\n",
    "print(\"Number of rows after removing missing spec_id:\", len(df))\n",
    "columns_to_keep.append('spec_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "806ace32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_grade(val):\n",
    "    s = str(val).lower().strip().replace(\"g\", \"\").replace(\"_\", \".\")\n",
    "    \n",
    "    if s in ['nan', 'none', '', '0']:\n",
    "        return np.nan\n",
    "\n",
    "    if 'auth' in s:\n",
    "        return np.nan\n",
    "\n",
    "    if any(x in s for x in ['pristine', 'perfect', '10p', '10b']):\n",
    "        return 10.5\n",
    "\n",
    "    match = re.search(r\"(\\d+(\\.\\d+)?)\", s)\n",
    "    if match:\n",
    "        try:\n",
    "            return float(match.group(1))\n",
    "        except ValueError:\n",
    "            return np.nan\n",
    "\n",
    "    return np.nan\n",
    "\n",
    "def process_grade(val):\n",
    "    if pd.isna(val):\n",
    "        return np.nan, np.nan\n",
    "    floor_val = np.floor(val)\n",
    "    half_val = 1 if (val - floor_val) > 0 else 0\n",
    "    return floor_val, half_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "333d25e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts of each grade before cleaning:\n",
      "gemrate_data.grade\n",
      "g10                  185653\n",
      "g9                   105471\n",
      "g8                    36880\n",
      "g7                    12944\n",
      "g10pristine           11246\n",
      "g6                     8142\n",
      "g9_5                   4924\n",
      "g5                     4450\n",
      "g8_5                   4268\n",
      "g4                     2470\n",
      "g10p                   1497\n",
      "g3                     1204\n",
      "g1                     1179\n",
      "g7_5                    996\n",
      "g2                      651\n",
      "auth                    455\n",
      "g10b                    427\n",
      "g6_5                    394\n",
      "g5_5                    247\n",
      "g4_5                    120\n",
      "g10perfect              110\n",
      "authentic                81\n",
      "g3_5                     78\n",
      "g2_5                     46\n",
      "g1_5                     45\n",
      "g0                       24\n",
      "authentic_altered        17\n",
      "NaN                       5\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Counts of each grade before cleaning:\")\n",
    "print(df['gemrate_data.grade'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76266665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grade\n",
      "10.5     13280\n",
      "10.0    185653\n",
      "9.5       4924\n",
      "9.0     105471\n",
      "8.5       4268\n",
      "8.0      36880\n",
      "7.5        996\n",
      "7.0      12944\n",
      "6.5        394\n",
      "6.0       8142\n",
      "5.5        247\n",
      "5.0       4450\n",
      "4.5        120\n",
      "4.0       2470\n",
      "3.5         78\n",
      "3.0       1204\n",
      "2.5         46\n",
      "2.0        651\n",
      "1.5         45\n",
      "1.0       1179\n",
      "Name: count, dtype: int64\n",
      "Number of rows after cleaning grade 383442\n"
     ]
    }
   ],
   "source": [
    "df[\"grade\"] = df[\"gemrate_data.grade\"].apply(clean_grade)\n",
    "df = df.dropna(subset=['grade'])\n",
    "print(df['grade'].value_counts().sort_index(ascending=False))\n",
    "print(\"Number of rows after cleaning grade\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e68517de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grade  half_grade\n",
      "10.0   1.0            13280\n",
      "       0.0           185653\n",
      "9.0    1.0             4924\n",
      "       0.0           105471\n",
      "8.0    1.0             4268\n",
      "       0.0            36880\n",
      "7.0    1.0              996\n",
      "       0.0            12944\n",
      "6.0    1.0              394\n",
      "       0.0             8142\n",
      "5.0    1.0              247\n",
      "       0.0             4450\n",
      "4.0    1.0              120\n",
      "       0.0             2470\n",
      "3.0    1.0               78\n",
      "       0.0             1204\n",
      "2.0    1.0               46\n",
      "       0.0              651\n",
      "1.0    1.0               45\n",
      "       0.0             1179\n",
      "Name: count, dtype: int64\n",
      "Number of rows after cleaning grade 383442\n"
     ]
    }
   ],
   "source": [
    "df[['grade', 'half_grade']] = df['grade'].apply(lambda x: pd.Series(process_grade(x)))\n",
    "print(df[['grade', 'half_grade']].value_counts().sort_index(ascending=False))\n",
    "print(\"Number of rows after cleaning grade\", len(df))\n",
    "columns_to_keep.append('grade')\n",
    "columns_to_keep.append('half_grade')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9950880",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "911675c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currnecy of sale:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "item_data.price\n",
       "US                     215326\n",
       "$ (No Country Code)    154092\n",
       "C                        5692\n",
       "EUR                      4253\n",
       "GBP                      2431\n",
       "AU                       1648\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def group_currencies(val):\n",
    "    s = str(val).strip()\n",
    "\n",
    "    if s.startswith('$') or s[0].isdigit():\n",
    "        return '$ (No Country Code)'\n",
    "\n",
    "    return s\n",
    "\n",
    "currency_groups = df['item_data.price'].str.split().str[0].apply(group_currencies)\n",
    "\n",
    "print(\"Currnecy of sale:\")\n",
    "currency_groups.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ae53b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after cleaning sale price 369418\n"
     ]
    }
   ],
   "source": [
    "df = df.loc[currency_groups.isin(['$ (No Country Code)', 'US'])]\n",
    "df['price'] = df['item_data.price'].astype(str).str.replace(r'\\D+', '', regex=True).astype(int)\n",
    "print(\"Number of rows after cleaning sale price\", len(df))\n",
    "columns_to_keep.append('price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74363247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of bids filter at >=3\n",
      "Number of bids raw:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    369418.000000\n",
       "mean         15.412484\n",
       "std          12.413304\n",
       "min           0.000000\n",
       "25%           7.000000\n",
       "50%          13.000000\n",
       "75%          21.000000\n",
       "max         629.000000\n",
       "Name: item_data.number_of_bids, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Number of bids filter at >={NUMBER_OF_BIDS_FILTER}\")\n",
    "print(\"Number of bids raw:\")\n",
    "df[\"item_data.number_of_bids\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62be0827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    328093.000000\n",
       "mean         17.193396\n",
       "std          12.046500\n",
       "min           3.000000\n",
       "25%           9.000000\n",
       "50%          14.000000\n",
       "75%          22.000000\n",
       "max         629.000000\n",
       "Name: number_of_bids, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"number_of_bids\"] = df[\"item_data.number_of_bids\"].astype(int).dropna()\n",
    "df = df.loc[df[\"number_of_bids\"] >= NUMBER_OF_BIDS_FILTER]\n",
    "columns_to_keep.append(\"number_of_bids\")\n",
    "df[\"number_of_bids\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "top_seller_feat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 sellers: ['PSA', 'ZandGEmporium', 'Probstein Auctions', 'dcsports87 sports cards', 'PC Sportscards']\n",
      "Top seller distribution:\n",
      "top_seller\n",
      "0    223627\n",
      "1    104466\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def get_top_sellers(df, column_name='item_data.seller_name', top_n=TOP_N_SELLERS):\n",
    "    top_sellers = df[column_name].value_counts().head(top_n).index.tolist()\n",
    "    return top_sellers\n",
    "\n",
    "top_sellers = get_top_sellers(df)\n",
    "print(f\"Top {len(top_sellers)} sellers: {top_sellers}\")\n",
    "\n",
    "df['top_seller'] = df['item_data.seller_name'].apply(lambda x: 1 if x in top_sellers else 0)\n",
    "columns_to_keep.append('top_seller')\n",
    "print(\"Top seller distribution:\")\n",
    "print(df['top_seller'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d64c9656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of each grader: grading_company\n",
      "PSA    283653\n",
      "CGC     38268\n",
      "BGS      5933\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Count of each grader:\", df['grading_company'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32a0d7d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added columns: ['grade_co_BGS', 'grade_co_CGC', 'grade_co_PSA']\n"
     ]
    }
   ],
   "source": [
    "dummies = pd.get_dummies(df['grading_company'], prefix='grade_co', dtype=int)\n",
    "df = pd.concat([df, dummies], axis=1)\n",
    "columns_to_keep.extend(dummies.columns.tolist())\n",
    "print(\"Added columns:\", dummies.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7bd948bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0942d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transactions per week:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "date\n",
       "2025-09-07    17820\n",
       "2025-09-14    28907\n",
       "2025-09-21    70512\n",
       "2025-09-28    20760\n",
       "2025-10-05    18105\n",
       "2025-10-12    18628\n",
       "2025-10-19    24753\n",
       "2025-10-26    31561\n",
       "2025-11-02    20234\n",
       "2025-11-09    19040\n",
       "2025-11-16    19743\n",
       "2025-11-23    12577\n",
       "2025-11-30    20588\n",
       "2025-12-07     4865\n",
       "Freq: W-SUN, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weekly_grouper = pd.Grouper(key='date', freq='W')\n",
    "print(\"Transactions per week:\")\n",
    "df.groupby(weekly_grouper).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bcbd2b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_previous_sale_features(df, n_sales_back):\n",
    "    \"\"\"\n",
    "    Create features from previous individual sales within each spec_id/grade group.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with columns spec_id, grade, date, price, half_grade, \n",
    "            grade_co_BGS, grade_co_CGC, grade_co_PSA, top_seller\n",
    "        n_sales_back: Number of previous sales to look back (e.g., 3 means get features \n",
    "                      from the 1st, 2nd, and 3rd previous sales)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with new columns for each previous sale:\n",
    "        - prev_{n}_price: price of nth previous sale\n",
    "        - prev_{n}_half_grade: half_grade of nth previous sale\n",
    "        - prev_{n}_grade_co_BGS: grade_co_BGS of nth previous sale\n",
    "        - prev_{n}_grade_co_CGC: grade_co_CGC of nth previous sale\n",
    "        - prev_{n}_grade_co_PSA: grade_co_PSA of nth previous sale\n",
    "        - prev_{n}_top_seller: top_seller of nth previous sale\n",
    "        - prev_{n}_days_ago: number of days between current sale and nth previous sale\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    df = df.sort_values(['spec_id', 'grade', 'date']).reset_index(drop=True)\n",
    "    \n",
    "    feature_cols = ['price', 'half_grade', 'grade_co_BGS', 'grade_co_CGC', 'grade_co_PSA', 'top_seller']\n",
    "    \n",
    "    new_columns = []\n",
    "    \n",
    "    for n in range(1, n_sales_back + 1):\n",
    "        suffix = f'prev_{n}'\n",
    "        \n",
    "        for col in feature_cols:\n",
    "            new_col_name = f'{suffix}_{col}'\n",
    "            df[new_col_name] = df.groupby(['spec_id', 'grade'])[col].shift(n)\n",
    "            new_columns.append(new_col_name)\n",
    "        \n",
    "        days_col_name = f'{suffix}_days_ago'\n",
    "        prev_date = df.groupby(['spec_id', 'grade'])['date'].shift(n)\n",
    "        df[days_col_name] = (df['date'] - prev_date).dt.days\n",
    "        new_columns.append(days_col_name)\n",
    "    \n",
    "    print(f\"Created {len(new_columns)} new previous sale columns:\")\n",
    "    print(new_columns)\n",
    "    print(\"\\nNull counts for previous sale features:\")\n",
    "    print(df[new_columns].isnull().sum())\n",
    "    \n",
    "    return df, new_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "71a61607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 35 new previous sale columns:\n",
      "['prev_1_price', 'prev_1_half_grade', 'prev_1_grade_co_BGS', 'prev_1_grade_co_CGC', 'prev_1_grade_co_PSA', 'prev_1_top_seller', 'prev_1_days_ago', 'prev_2_price', 'prev_2_half_grade', 'prev_2_grade_co_BGS', 'prev_2_grade_co_CGC', 'prev_2_grade_co_PSA', 'prev_2_top_seller', 'prev_2_days_ago', 'prev_3_price', 'prev_3_half_grade', 'prev_3_grade_co_BGS', 'prev_3_grade_co_CGC', 'prev_3_grade_co_PSA', 'prev_3_top_seller', 'prev_3_days_ago', 'prev_4_price', 'prev_4_half_grade', 'prev_4_grade_co_BGS', 'prev_4_grade_co_CGC', 'prev_4_grade_co_PSA', 'prev_4_top_seller', 'prev_4_days_ago', 'prev_5_price', 'prev_5_half_grade', 'prev_5_grade_co_BGS', 'prev_5_grade_co_CGC', 'prev_5_grade_co_PSA', 'prev_5_top_seller', 'prev_5_days_ago']\n",
      "\n",
      "Null counts for previous sale features:\n",
      "prev_1_price            84596\n",
      "prev_1_half_grade       84596\n",
      "prev_1_grade_co_BGS     84596\n",
      "prev_1_grade_co_CGC     84596\n",
      "prev_1_grade_co_PSA     84596\n",
      "prev_1_top_seller       84596\n",
      "prev_1_days_ago         84596\n",
      "prev_2_price           114831\n",
      "prev_2_half_grade      114831\n",
      "prev_2_grade_co_BGS    114831\n",
      "prev_2_grade_co_CGC    114831\n",
      "prev_2_grade_co_PSA    114831\n",
      "prev_2_top_seller      114831\n",
      "prev_2_days_ago        114831\n",
      "prev_3_price           133106\n",
      "prev_3_half_grade      133106\n",
      "prev_3_grade_co_BGS    133106\n",
      "prev_3_grade_co_CGC    133106\n",
      "prev_3_grade_co_PSA    133106\n",
      "prev_3_top_seller      133106\n",
      "prev_3_days_ago        133106\n",
      "prev_4_price           146299\n",
      "prev_4_half_grade      146299\n",
      "prev_4_grade_co_BGS    146299\n",
      "prev_4_grade_co_CGC    146299\n",
      "prev_4_grade_co_PSA    146299\n",
      "prev_4_top_seller      146299\n",
      "prev_4_days_ago        146299\n",
      "prev_5_price           156636\n",
      "prev_5_half_grade      156636\n",
      "prev_5_grade_co_BGS    156636\n",
      "prev_5_grade_co_CGC    156636\n",
      "prev_5_grade_co_PSA    156636\n",
      "prev_5_top_seller      156636\n",
      "prev_5_days_ago        156636\n",
      "dtype: int64\n",
      "\n",
      "Sample of previous sale features:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spec_id</th>\n",
       "      <th>grade</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>prev_1_price</th>\n",
       "      <th>prev_1_days_ago</th>\n",
       "      <th>prev_2_price</th>\n",
       "      <th>prev_2_days_ago</th>\n",
       "      <th>prev_3_price</th>\n",
       "      <th>prev_3_days_ago</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>179360</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2025-09-14</td>\n",
       "      <td>3300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>180294</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2025-09-03</td>\n",
       "      <td>5300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>181923</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2025-09-11</td>\n",
       "      <td>12350</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>182654</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2025-09-07</td>\n",
       "      <td>4800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>184362</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2025-09-04</td>\n",
       "      <td>6660</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>188365</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2025-10-20</td>\n",
       "      <td>22438</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>192774</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2025-11-02</td>\n",
       "      <td>6200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>192974</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2025-09-03</td>\n",
       "      <td>7300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>220135</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2025-09-22</td>\n",
       "      <td>10000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>220135</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2025-09-25</td>\n",
       "      <td>6000</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>220135</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2025-11-08</td>\n",
       "      <td>2700</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>240919</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2025-11-30</td>\n",
       "      <td>10250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>242600</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2025-11-11</td>\n",
       "      <td>2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>254312</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2025-11-09</td>\n",
       "      <td>4800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>254752</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2025-10-16</td>\n",
       "      <td>4771</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    spec_id  grade       date  price  prev_1_price  prev_1_days_ago  \\\n",
       "0    179360    6.0 2025-09-14   3300           NaN              NaN   \n",
       "1    180294    6.0 2025-09-03   5300           NaN              NaN   \n",
       "2    181923    8.0 2025-09-11  12350           NaN              NaN   \n",
       "3    182654    5.0 2025-09-07   4800           NaN              NaN   \n",
       "4    184362    5.0 2025-09-04   6660           NaN              NaN   \n",
       "5    188365    4.0 2025-10-20  22438           NaN              NaN   \n",
       "6    192774    8.0 2025-11-02   6200           NaN              NaN   \n",
       "7    192974    5.0 2025-09-03   7300           NaN              NaN   \n",
       "8    220135    8.0 2025-09-22  10000           NaN              NaN   \n",
       "9    220135    8.0 2025-09-25   6000       10000.0              3.0   \n",
       "10   220135    8.0 2025-11-08   2700        6000.0             44.0   \n",
       "11   240919    8.0 2025-11-30  10250           NaN              NaN   \n",
       "12   242600    8.0 2025-11-11   2500           NaN              NaN   \n",
       "13   254312   10.0 2025-11-09   4800           NaN              NaN   \n",
       "14   254752    8.0 2025-10-16   4771           NaN              NaN   \n",
       "\n",
       "    prev_2_price  prev_2_days_ago  prev_3_price  prev_3_days_ago  \n",
       "0            NaN              NaN           NaN              NaN  \n",
       "1            NaN              NaN           NaN              NaN  \n",
       "2            NaN              NaN           NaN              NaN  \n",
       "3            NaN              NaN           NaN              NaN  \n",
       "4            NaN              NaN           NaN              NaN  \n",
       "5            NaN              NaN           NaN              NaN  \n",
       "6            NaN              NaN           NaN              NaN  \n",
       "7            NaN              NaN           NaN              NaN  \n",
       "8            NaN              NaN           NaN              NaN  \n",
       "9            NaN              NaN           NaN              NaN  \n",
       "10       10000.0             47.0           NaN              NaN  \n",
       "11           NaN              NaN           NaN              NaN  \n",
       "12           NaN              NaN           NaN              NaN  \n",
       "13           NaN              NaN           NaN              NaN  \n",
       "14           NaN              NaN           NaN              NaN  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df, prev_sale_col_names = create_previous_sale_features(df, n_sales_back=N_SALES_BACK)\n",
    "columns_to_keep.extend(prev_sale_col_names)\n",
    "\n",
    "print(\"\\nSample of previous sale features:\")\n",
    "sample_cols = ['spec_id', 'grade', 'date', 'price', 'prev_1_price', 'prev_1_days_ago', \n",
    "               'prev_2_price', 'prev_2_days_ago', 'prev_3_price', 'prev_3_days_ago']\n",
    "df[sample_cols].head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fde4908c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lookback_features(df, weeks_back_list):\n",
    "    \"\"\"\n",
    "    Create lookback features for the dataframe.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with columns spec_id, grade, date, price, half_grade, \n",
    "            grade_co_BGS, grade_co_CGC, grade_co_PSA\n",
    "        weeks_back_list: List of weeks to look back (e.g., [1, 2, 4] for 1, 2, and 4 weeks ago)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with new columns for each lookback period\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    df = df.sort_values(['spec_id', 'grade', 'date']).reset_index(drop=True)\n",
    "\n",
    "    df['week'] = df['date'].dt.to_period('W').dt.start_time\n",
    "\n",
    "    agg_cols = ['price', 'half_grade', 'top_seller', 'grade_co_BGS', 'grade_co_CGC', 'grade_co_PSA']\n",
    "    \n",
    "    weekly_agg = df.groupby(['spec_id', 'grade', 'week'])[agg_cols].mean().reset_index()\n",
    "    weekly_agg.columns = ['spec_id', 'grade', 'week', 'avg_price', 'avg_half_grade', 'avg_top_seller',\n",
    "                          'avg_grade_co_BGS', 'avg_grade_co_CGC', 'avg_grade_co_PSA']\n",
    "    \n",
    "    result_df = df.copy()\n",
    "    new_columns = []\n",
    "    \n",
    "    for w in weeks_back_list:\n",
    "        shifted_agg = weekly_agg.copy()\n",
    "        shifted_agg['join_week'] = shifted_agg['week'] + pd.Timedelta(weeks=w)\n",
    "\n",
    "        suffix = f'_{w}w_ago'\n",
    "        feature_cols = ['avg_price', 'avg_half_grade', 'avg_top_seller', 'avg_grade_co_BGS', 'avg_grade_co_CGC', 'avg_grade_co_PSA']\n",
    "        rename_dict = {col: f'{col}{suffix}' for col in feature_cols}\n",
    "        shifted_agg = shifted_agg.rename(columns=rename_dict)\n",
    "        \n",
    "        new_col_names = list(rename_dict.values())\n",
    "        new_columns.extend(new_col_names)\n",
    "\n",
    "        result_df = result_df.merge(\n",
    "            shifted_agg[['spec_id', 'grade', 'join_week'] + new_col_names],\n",
    "            left_on=['spec_id', 'grade', 'week'],\n",
    "            right_on=['spec_id', 'grade', 'join_week'],\n",
    "            how='left'\n",
    "        )\n",
    "        result_df = result_df.drop(columns=['join_week'])\n",
    "    \n",
    "    print(f\"Created {len(new_columns)} new lookback columns:\")\n",
    "    print(new_columns)\n",
    "    print(\"Null counts for lookback features:\")\n",
    "    print(result_df[new_columns].isnull().sum())\n",
    "    \n",
    "    return result_df, new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e487cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 24 new lookback columns:\n",
      "['avg_price_1w_ago', 'avg_half_grade_1w_ago', 'avg_top_seller_1w_ago', 'avg_grade_co_BGS_1w_ago', 'avg_grade_co_CGC_1w_ago', 'avg_grade_co_PSA_1w_ago', 'avg_price_2w_ago', 'avg_half_grade_2w_ago', 'avg_top_seller_2w_ago', 'avg_grade_co_BGS_2w_ago', 'avg_grade_co_CGC_2w_ago', 'avg_grade_co_PSA_2w_ago', 'avg_price_3w_ago', 'avg_half_grade_3w_ago', 'avg_top_seller_3w_ago', 'avg_grade_co_BGS_3w_ago', 'avg_grade_co_CGC_3w_ago', 'avg_grade_co_PSA_3w_ago', 'avg_price_4w_ago', 'avg_half_grade_4w_ago', 'avg_top_seller_4w_ago', 'avg_grade_co_BGS_4w_ago', 'avg_grade_co_CGC_4w_ago', 'avg_grade_co_PSA_4w_ago']\n",
      "Null counts for lookback features:\n",
      "avg_price_1w_ago           151223\n",
      "avg_half_grade_1w_ago      151223\n",
      "avg_top_seller_1w_ago      151223\n",
      "avg_grade_co_BGS_1w_ago    151223\n",
      "avg_grade_co_CGC_1w_ago    151223\n",
      "avg_grade_co_PSA_1w_ago    151223\n",
      "avg_price_2w_ago           171306\n",
      "avg_half_grade_2w_ago      171306\n",
      "avg_top_seller_2w_ago      171306\n",
      "avg_grade_co_BGS_2w_ago    171306\n",
      "avg_grade_co_CGC_2w_ago    171306\n",
      "avg_grade_co_PSA_2w_ago    171306\n",
      "avg_price_3w_ago           209490\n",
      "avg_half_grade_3w_ago      209490\n",
      "avg_top_seller_3w_ago      209490\n",
      "avg_grade_co_BGS_3w_ago    209490\n",
      "avg_grade_co_CGC_3w_ago    209490\n",
      "avg_grade_co_PSA_3w_ago    209490\n",
      "avg_price_4w_ago           220721\n",
      "avg_half_grade_4w_ago      220721\n",
      "avg_top_seller_4w_ago      220721\n",
      "avg_grade_co_BGS_4w_ago    220721\n",
      "avg_grade_co_CGC_4w_ago    220721\n",
      "avg_grade_co_PSA_4w_ago    220721\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df, lookback_col_names = create_lookback_features(df, weeks_back_list=WEEKS_BACK_LIST)\n",
    "columns_to_keep.extend(lookback_col_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08c7477a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_adjacent_grade_features(df, n_sales_back):\n",
    "    \"\"\"\n",
    "    Create features from previous n sales of adjacent grades (one above and one below).\n",
    "    For each row, looks up the most recent n sales of grade+1 and grade-1 within the same spec_id.\n",
    "    \n",
    "    For grade 10 rows, uses grade 10 as \"above\" since there's no grade 11.\n",
    "    For grade 1 rows, uses grade 1 as \"below\" since there's no grade 0.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with columns spec_id, grade, date, price, half_grade,\n",
    "            grade_co_BGS, grade_co_CGC, grade_co_PSA, top_seller\n",
    "        n_sales_back: Number of previous sales to look back\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with new columns for each adjacent grade's previous sales:\n",
    "        - prev_{n}_above_{feature}: nth previous sale feature from grade above\n",
    "        - prev_{n}_below_{feature}: nth previous sale feature from grade below\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df = df.sort_values(['spec_id', 'grade', 'date']).reset_index(drop=True)\n",
    "    \n",
    "    feature_cols = ['price', 'half_grade', 'grade_co_BGS', 'grade_co_CGC', 'grade_co_PSA', 'top_seller']\n",
    "    new_columns = []\n",
    "    \n",
    "    # Create reference data with cumulative sale index within each [spec_id, grade]\n",
    "    ref = df[['spec_id', 'grade', 'date'] + feature_cols].copy()\n",
    "    ref = ref.sort_values(['spec_id', 'grade', 'date']).reset_index(drop=True)\n",
    "    ref['_sale_idx'] = ref.groupby(['spec_id', 'grade']).cumcount()\n",
    "    \n",
    "    for direction, grade_offset in [('above', 1), ('below', -1)]:\n",
    "        # Calculate the target grade for lookup (clipped to valid range)\n",
    "        # For grade 10, use grade 10 as \"above\"; for grade 1, use grade 1 as \"below\"\n",
    "        target_grade = (df['grade'] + grade_offset).clip(lower=1.0, upper=10.0)\n",
    "        \n",
    "        # Prepare data for merge_asof to find most recent sale in target grade\n",
    "        df_lookup = pd.DataFrame({\n",
    "            'spec_id': df['spec_id'],\n",
    "            'orig_date': df['date'],\n",
    "            'target_grade': target_grade,\n",
    "            '_orig_row': range(len(df))\n",
    "        }).sort_values('orig_date')\n",
    "        \n",
    "        ref_for_asof = ref[['spec_id', 'grade', 'date', '_sale_idx']].copy()\n",
    "        ref_for_asof.columns = ['spec_id', 'target_grade', 'ref_date', '_sale_idx']\n",
    "        ref_for_asof = ref_for_asof.sort_values('ref_date')\n",
    "        \n",
    "        # Find the sale_idx of the most recent sale in target grade before each row's date\n",
    "        merged = pd.merge_asof(\n",
    "            df_lookup,\n",
    "            ref_for_asof,\n",
    "            left_on='orig_date',\n",
    "            right_on='ref_date',\n",
    "            by=['spec_id', 'target_grade'],\n",
    "            direction='backward',\n",
    "            allow_exact_matches=False\n",
    "        )\n",
    "        \n",
    "        for n in range(1, n_sales_back + 1):\n",
    "            suffix = f'prev_{n}_{direction}'\n",
    "            \n",
    "            # The nth previous has sale_idx = _sale_idx - (n-1)\n",
    "            merged['_lookup_idx'] = merged['_sale_idx'] - (n - 1)\n",
    "            \n",
    "            # Prepare lookup data from ref\n",
    "            ref_features = ref[['spec_id', 'grade', '_sale_idx', 'date'] + feature_cols].copy()\n",
    "            ref_features.columns = ['spec_id', 'target_grade', '_lookup_idx', 'prev_date'] + feature_cols\n",
    "            \n",
    "            # Join to get features\n",
    "            with_features = merged.merge(\n",
    "                ref_features,\n",
    "                on=['spec_id', 'target_grade', '_lookup_idx'],\n",
    "                how='left'\n",
    "            )\n",
    "            \n",
    "            # Sort back to original order\n",
    "            with_features = with_features.sort_values('_orig_row').reset_index(drop=True)\n",
    "            \n",
    "            # Add features to df\n",
    "            for col in feature_cols:\n",
    "                new_col_name = f'{suffix}_{col}'\n",
    "                df[new_col_name] = with_features[col].values\n",
    "                new_columns.append(new_col_name)\n",
    "            \n",
    "            days_col_name = f'{suffix}_days_ago'\n",
    "            df[days_col_name] = (with_features['orig_date'] - with_features['prev_date']).dt.days.values\n",
    "            new_columns.append(days_col_name)\n",
    "    \n",
    "    print(f\"Created {len(new_columns)} new adjacent grade columns:\")\n",
    "    print(new_columns)\n",
    "    print(\"\\nNull counts for adjacent grade features:\")\n",
    "    print(df[new_columns].isnull().sum())\n",
    "    \n",
    "    return df, new_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "463bbbd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 70 new adjacent grade columns:\n",
      "['prev_1_above_price', 'prev_1_above_half_grade', 'prev_1_above_grade_co_BGS', 'prev_1_above_grade_co_CGC', 'prev_1_above_grade_co_PSA', 'prev_1_above_top_seller', 'prev_1_above_days_ago', 'prev_2_above_price', 'prev_2_above_half_grade', 'prev_2_above_grade_co_BGS', 'prev_2_above_grade_co_CGC', 'prev_2_above_grade_co_PSA', 'prev_2_above_top_seller', 'prev_2_above_days_ago', 'prev_3_above_price', 'prev_3_above_half_grade', 'prev_3_above_grade_co_BGS', 'prev_3_above_grade_co_CGC', 'prev_3_above_grade_co_PSA', 'prev_3_above_top_seller', 'prev_3_above_days_ago', 'prev_4_above_price', 'prev_4_above_half_grade', 'prev_4_above_grade_co_BGS', 'prev_4_above_grade_co_CGC', 'prev_4_above_grade_co_PSA', 'prev_4_above_top_seller', 'prev_4_above_days_ago', 'prev_5_above_price', 'prev_5_above_half_grade', 'prev_5_above_grade_co_BGS', 'prev_5_above_grade_co_CGC', 'prev_5_above_grade_co_PSA', 'prev_5_above_top_seller', 'prev_5_above_days_ago', 'prev_1_below_price', 'prev_1_below_half_grade', 'prev_1_below_grade_co_BGS', 'prev_1_below_grade_co_CGC', 'prev_1_below_grade_co_PSA', 'prev_1_below_top_seller', 'prev_1_below_days_ago', 'prev_2_below_price', 'prev_2_below_half_grade', 'prev_2_below_grade_co_BGS', 'prev_2_below_grade_co_CGC', 'prev_2_below_grade_co_PSA', 'prev_2_below_top_seller', 'prev_2_below_days_ago', 'prev_3_below_price', 'prev_3_below_half_grade', 'prev_3_below_grade_co_BGS', 'prev_3_below_grade_co_CGC', 'prev_3_below_grade_co_PSA', 'prev_3_below_top_seller', 'prev_3_below_days_ago', 'prev_4_below_price', 'prev_4_below_half_grade', 'prev_4_below_grade_co_BGS', 'prev_4_below_grade_co_CGC', 'prev_4_below_grade_co_PSA', 'prev_4_below_top_seller', 'prev_4_below_days_ago', 'prev_5_below_price', 'prev_5_below_half_grade', 'prev_5_below_grade_co_BGS', 'prev_5_below_grade_co_CGC', 'prev_5_below_grade_co_PSA', 'prev_5_below_top_seller', 'prev_5_below_days_ago']\n",
      "\n",
      "Null counts for adjacent grade features:\n",
      "prev_1_above_price            85982\n",
      "prev_1_above_half_grade       85982\n",
      "prev_1_above_grade_co_BGS     85982\n",
      "prev_1_above_grade_co_CGC     85982\n",
      "prev_1_above_grade_co_PSA     85982\n",
      "                              ...  \n",
      "prev_5_below_grade_co_BGS    215012\n",
      "prev_5_below_grade_co_CGC    215012\n",
      "prev_5_below_grade_co_PSA    215012\n",
      "prev_5_below_top_seller      215012\n",
      "prev_5_below_days_ago        215012\n",
      "Length: 70, dtype: int64\n",
      "\n",
      "Sample of adjacent grade features:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spec_id</th>\n",
       "      <th>grade</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>prev_1_above_price</th>\n",
       "      <th>prev_1_above_days_ago</th>\n",
       "      <th>prev_1_below_price</th>\n",
       "      <th>prev_1_below_days_ago</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>179360</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2025-09-14</td>\n",
       "      <td>3300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>180294</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2025-09-03</td>\n",
       "      <td>5300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>181923</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2025-09-11</td>\n",
       "      <td>12350</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>182654</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2025-09-07</td>\n",
       "      <td>4800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>184362</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2025-09-04</td>\n",
       "      <td>6660</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>188365</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2025-10-20</td>\n",
       "      <td>22438</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>192774</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2025-11-02</td>\n",
       "      <td>6200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>192974</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2025-09-03</td>\n",
       "      <td>7300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>220135</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2025-09-22</td>\n",
       "      <td>10000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>220135</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2025-09-25</td>\n",
       "      <td>6000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>220135</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2025-11-08</td>\n",
       "      <td>2700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>240919</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2025-11-30</td>\n",
       "      <td>10250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>242600</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2025-11-11</td>\n",
       "      <td>2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>254312</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2025-11-09</td>\n",
       "      <td>4800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>254752</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2025-10-16</td>\n",
       "      <td>4771</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    spec_id  grade       date  price  prev_1_above_price  \\\n",
       "0    179360    6.0 2025-09-14   3300                 NaN   \n",
       "1    180294    6.0 2025-09-03   5300                 NaN   \n",
       "2    181923    8.0 2025-09-11  12350                 NaN   \n",
       "3    182654    5.0 2025-09-07   4800                 NaN   \n",
       "4    184362    5.0 2025-09-04   6660                 NaN   \n",
       "5    188365    4.0 2025-10-20  22438                 NaN   \n",
       "6    192774    8.0 2025-11-02   6200                 NaN   \n",
       "7    192974    5.0 2025-09-03   7300                 NaN   \n",
       "8    220135    8.0 2025-09-22  10000                 NaN   \n",
       "9    220135    8.0 2025-09-25   6000                 NaN   \n",
       "10   220135    8.0 2025-11-08   2700                 NaN   \n",
       "11   240919    8.0 2025-11-30  10250                 NaN   \n",
       "12   242600    8.0 2025-11-11   2500                 NaN   \n",
       "13   254312   10.0 2025-11-09   4800                 NaN   \n",
       "14   254752    8.0 2025-10-16   4771                 NaN   \n",
       "\n",
       "    prev_1_above_days_ago  prev_1_below_price  prev_1_below_days_ago  \n",
       "0                     NaN                 NaN                    NaN  \n",
       "1                     NaN                 NaN                    NaN  \n",
       "2                     NaN                 NaN                    NaN  \n",
       "3                     NaN                 NaN                    NaN  \n",
       "4                     NaN                 NaN                    NaN  \n",
       "5                     NaN                 NaN                    NaN  \n",
       "6                     NaN                 NaN                    NaN  \n",
       "7                     NaN                 NaN                    NaN  \n",
       "8                     NaN                 NaN                    NaN  \n",
       "9                     NaN                 NaN                    NaN  \n",
       "10                    NaN                 NaN                    NaN  \n",
       "11                    NaN                 NaN                    NaN  \n",
       "12                    NaN                 NaN                    NaN  \n",
       "13                    NaN                 NaN                    NaN  \n",
       "14                    NaN                 NaN                    NaN  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df, adjacent_grade_col_names = create_adjacent_grade_features(df, n_sales_back=N_SALES_BACK)\n",
    "columns_to_keep.extend(adjacent_grade_col_names)\n",
    "\n",
    "print(\"\\nSample of adjacent grade features:\")\n",
    "sample_cols = ['spec_id', 'grade', 'date', 'price', \n",
    "               'prev_1_above_price', 'prev_1_above_days_ago',\n",
    "               'prev_1_below_price', 'prev_1_below_days_ago']\n",
    "df[sample_cols].head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "368540b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample of lookback features:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>spec_id</th>\n",
       "      <th>grade</th>\n",
       "      <th>half_grade</th>\n",
       "      <th>price</th>\n",
       "      <th>number_of_bids</th>\n",
       "      <th>top_seller</th>\n",
       "      <th>grade_co_BGS</th>\n",
       "      <th>grade_co_CGC</th>\n",
       "      <th>grade_co_PSA</th>\n",
       "      <th>...</th>\n",
       "      <th>prev_4_below_grade_co_PSA</th>\n",
       "      <th>prev_4_below_top_seller</th>\n",
       "      <th>prev_4_below_days_ago</th>\n",
       "      <th>prev_5_below_price</th>\n",
       "      <th>prev_5_below_half_grade</th>\n",
       "      <th>prev_5_below_grade_co_BGS</th>\n",
       "      <th>prev_5_below_grade_co_CGC</th>\n",
       "      <th>prev_5_below_grade_co_PSA</th>\n",
       "      <th>prev_5_below_top_seller</th>\n",
       "      <th>prev_5_below_days_ago</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-09-14</td>\n",
       "      <td>179360</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3300</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-09-03</td>\n",
       "      <td>180294</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5300</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-09-11</td>\n",
       "      <td>181923</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12350</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-09-07</td>\n",
       "      <td>182654</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4800</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-09-04</td>\n",
       "      <td>184362</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6660</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-10-20</td>\n",
       "      <td>188365</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22438</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-11-02</td>\n",
       "      <td>192774</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6200</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2025-09-03</td>\n",
       "      <td>192974</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7300</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2025-09-22</td>\n",
       "      <td>220135</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2025-09-25</td>\n",
       "      <td>220135</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6000</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows  140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  spec_id  grade  half_grade  price  number_of_bids  top_seller  \\\n",
       "0 2025-09-14   179360    6.0         0.0   3300              14           0   \n",
       "1 2025-09-03   180294    6.0         0.0   5300               5           0   \n",
       "2 2025-09-11   181923    8.0         0.0  12350              15           0   \n",
       "3 2025-09-07   182654    5.0         0.0   4800               4           0   \n",
       "4 2025-09-04   184362    5.0         0.0   6660              10           0   \n",
       "5 2025-10-20   188365    4.0         0.0  22438              30           1   \n",
       "6 2025-11-02   192774    8.0         0.0   6200              16           1   \n",
       "7 2025-09-03   192974    5.0         0.0   7300               9           0   \n",
       "8 2025-09-22   220135    8.0         1.0  10000               5           0   \n",
       "9 2025-09-25   220135    8.0         1.0   6000              16           0   \n",
       "\n",
       "   grade_co_BGS  grade_co_CGC  grade_co_PSA  ...  prev_4_below_grade_co_PSA  \\\n",
       "0             0             0             1  ...                        NaN   \n",
       "1             0             0             1  ...                        NaN   \n",
       "2             0             0             1  ...                        NaN   \n",
       "3             0             0             1  ...                        NaN   \n",
       "4             0             0             1  ...                        NaN   \n",
       "5             0             0             1  ...                        NaN   \n",
       "6             0             0             1  ...                        NaN   \n",
       "7             0             0             1  ...                        NaN   \n",
       "8             1             0             0  ...                        NaN   \n",
       "9             1             0             0  ...                        NaN   \n",
       "\n",
       "   prev_4_below_top_seller  prev_4_below_days_ago  prev_5_below_price  \\\n",
       "0                      NaN                    NaN                 NaN   \n",
       "1                      NaN                    NaN                 NaN   \n",
       "2                      NaN                    NaN                 NaN   \n",
       "3                      NaN                    NaN                 NaN   \n",
       "4                      NaN                    NaN                 NaN   \n",
       "5                      NaN                    NaN                 NaN   \n",
       "6                      NaN                    NaN                 NaN   \n",
       "7                      NaN                    NaN                 NaN   \n",
       "8                      NaN                    NaN                 NaN   \n",
       "9                      NaN                    NaN                 NaN   \n",
       "\n",
       "   prev_5_below_half_grade  prev_5_below_grade_co_BGS  \\\n",
       "0                      NaN                        NaN   \n",
       "1                      NaN                        NaN   \n",
       "2                      NaN                        NaN   \n",
       "3                      NaN                        NaN   \n",
       "4                      NaN                        NaN   \n",
       "5                      NaN                        NaN   \n",
       "6                      NaN                        NaN   \n",
       "7                      NaN                        NaN   \n",
       "8                      NaN                        NaN   \n",
       "9                      NaN                        NaN   \n",
       "\n",
       "   prev_5_below_grade_co_CGC  prev_5_below_grade_co_PSA  \\\n",
       "0                        NaN                        NaN   \n",
       "1                        NaN                        NaN   \n",
       "2                        NaN                        NaN   \n",
       "3                        NaN                        NaN   \n",
       "4                        NaN                        NaN   \n",
       "5                        NaN                        NaN   \n",
       "6                        NaN                        NaN   \n",
       "7                        NaN                        NaN   \n",
       "8                        NaN                        NaN   \n",
       "9                        NaN                        NaN   \n",
       "\n",
       "   prev_5_below_top_seller  prev_5_below_days_ago  \n",
       "0                      NaN                    NaN  \n",
       "1                      NaN                    NaN  \n",
       "2                      NaN                    NaN  \n",
       "3                      NaN                    NaN  \n",
       "4                      NaN                    NaN  \n",
       "5                      NaN                    NaN  \n",
       "6                      NaN                    NaN  \n",
       "7                      NaN                    NaN  \n",
       "8                      NaN                    NaN  \n",
       "9                      NaN                    NaN  \n",
       "\n",
       "[10 rows x 140 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nSample of lookback features:\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b85ddd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_join_index_data(df, filepath):\n",
    "    \"\"\"\n",
    "    Loads index price data from CSV and joins it onto the dataframe by date.\n",
    "    Calculates additional index features before merging.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with a 'date' column (datetime)\n",
    "        filepath: Path to the index CSV file\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with index columns added:\n",
    "        - index_value: raw index value\n",
    "        - index_change_1d: change from previous day\n",
    "        - index_change_1w: change from previous week (7 days)\n",
    "        - index_ema_12: 12-day exponential moving average\n",
    "        - index_ema_26: 26-day exponential moving average\n",
    "    \"\"\"\n",
    "    index_df = pd.read_csv(filepath)\n",
    "    index_df['date'] = pd.to_datetime(index_df['date'])\n",
    "    \n",
    "    index_df = index_df.sort_values('date').reset_index(drop=True)\n",
    "    \n",
    "    index_df['index_change_1d'] = index_df['index_value'].diff(1)\n",
    "    \n",
    "    index_df['index_change_1w'] = index_df['index_value'].diff(7)\n",
    "    \n",
    "    index_df['index_ema_12'] = index_df['index_value'].ewm(span=12, adjust=False).mean()\n",
    "    \n",
    "    index_df['index_ema_26'] = index_df['index_value'].ewm(span=26, adjust=False).mean()\n",
    "    \n",
    "    df = df.merge(index_df, on='date', how='left')\n",
    "    \n",
    "    print(f\"Loaded {len(index_df)} index data points from {filepath}\")\n",
    "    print(f\"Index date range: {index_df['date'].min()} to {index_df['date'].max()}\")\n",
    "    print(f\"Null index values after join: {df['index_value'].isna().sum()}\")\n",
    "    print(\"Added index features: index_change_1d, index_change_1w, index_ema_12, index_ema_26\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e33d40bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 86 index data points from index.csv\n",
      "Index date range: 2025-09-08 00:00:00 to 2025-12-04 00:00:00\n",
      "Null index values after join: 23722\n",
      "Added index features: index_change_1d, index_change_1w, index_ema_12, index_ema_26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>index_value</th>\n",
       "      <th>index_change_1d</th>\n",
       "      <th>index_change_1w</th>\n",
       "      <th>index_ema_12</th>\n",
       "      <th>index_ema_26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-09-14</td>\n",
       "      <td>1010.320158</td>\n",
       "      <td>74.342627</td>\n",
       "      <td>NaN</td>\n",
       "      <td>994.706023</td>\n",
       "      <td>997.988710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-09-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-09-11</td>\n",
       "      <td>1031.257319</td>\n",
       "      <td>-8.418367</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1012.403235</td>\n",
       "      <td>1006.437334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-09-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-09-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-10-20</td>\n",
       "      <td>1177.144862</td>\n",
       "      <td>9.361181</td>\n",
       "      <td>-4.655270</td>\n",
       "      <td>1189.078664</td>\n",
       "      <td>1175.643340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-11-02</td>\n",
       "      <td>1134.793513</td>\n",
       "      <td>1.498461</td>\n",
       "      <td>-22.109628</td>\n",
       "      <td>1155.848581</td>\n",
       "      <td>1163.503677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2025-09-22</td>\n",
       "      <td>1160.547866</td>\n",
       "      <td>69.067902</td>\n",
       "      <td>185.409533</td>\n",
       "      <td>1038.324649</td>\n",
       "      <td>1017.636823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2025-09-25</td>\n",
       "      <td>1214.091923</td>\n",
       "      <td>7.921530</td>\n",
       "      <td>218.131376</td>\n",
       "      <td>1104.526931</td>\n",
       "      <td>1056.414655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2025-11-08</td>\n",
       "      <td>1117.499604</td>\n",
       "      <td>-11.158820</td>\n",
       "      <td>-15.795448</td>\n",
       "      <td>1138.907252</td>\n",
       "      <td>1151.056077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  index_value  index_change_1d  index_change_1w  index_ema_12  \\\n",
       "0  2025-09-14  1010.320158        74.342627              NaN    994.706023   \n",
       "1  2025-09-03          NaN              NaN              NaN           NaN   \n",
       "2  2025-09-11  1031.257319        -8.418367              NaN   1012.403235   \n",
       "3  2025-09-07          NaN              NaN              NaN           NaN   \n",
       "4  2025-09-04          NaN              NaN              NaN           NaN   \n",
       "5  2025-10-20  1177.144862         9.361181        -4.655270   1189.078664   \n",
       "6  2025-11-02  1134.793513         1.498461       -22.109628   1155.848581   \n",
       "8  2025-09-22  1160.547866        69.067902       185.409533   1038.324649   \n",
       "9  2025-09-25  1214.091923         7.921530       218.131376   1104.526931   \n",
       "10 2025-11-08  1117.499604       -11.158820       -15.795448   1138.907252   \n",
       "\n",
       "    index_ema_26  \n",
       "0     997.988710  \n",
       "1            NaN  \n",
       "2    1006.437334  \n",
       "3            NaN  \n",
       "4            NaN  \n",
       "5    1175.643340  \n",
       "6    1163.503677  \n",
       "8    1017.636823  \n",
       "9    1056.414655  \n",
       "10   1151.056077  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_and_join_index_data(df, INDEX_FILE)\n",
    "columns_to_keep.extend(['index_value', 'index_change_1d', 'index_change_1w', 'index_ema_12', 'index_ema_26'])\n",
    "df[['date', 'index_value', 'index_change_1d', 'index_change_1w', 'index_ema_12', 'index_ema_26']].drop_duplicates().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e7eda428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final number of rows: 231644\n",
      "Final number of columns: 144\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna(subset=['index_value', 'prev_1_price'])\n",
    "df = df[columns_to_keep]\n",
    "print(\"Final number of rows:\", len(df))\n",
    "print(\"Final number of columns:\", len(df.columns.tolist()))\n",
    "df.to_csv(FEATURES_PREPPED_FILE, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
