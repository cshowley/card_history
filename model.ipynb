{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa675797",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63516c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_PREPPED_FILE = \"features_prepped.csv\"\n",
    "TRAIN_TEST_SPLIT = 0.9\n",
    "VAL_TEST_SPLIT = 0.9\n",
    "START_DATE = datetime(2025,9,8) + timedelta(days=28)\n",
    "BAD_FEATURES = []\n",
    "TOP_100 = [2637208, 2674067, 2674069, 2677746, 2691590, 2739813, 2813189, 2813194, 2813195, 2819449, 2822887, 2840431, 2841189, 2855586, 2855595, 2857178, 3690505, 3690510, 4039724, 4189521, 4463773, 4580598, 5192206, 5192221, 5192225, 5245545, 5257669, 5658823, 5664444, 5683132, 5683135, 5683137, 5698506, 5698507, 5703921, 5710675, 5730396, 5823149, 5823150, 5850773, 5851707, 5955504, 5955510, 5955515, 5973485, 6049412, 6049413, 6256793, 6451779, 7210406, 7249979, 7379752, 7622814, 7622840, 7635753, 7653413, 7855462, 7869313, 7915951, 7917434, 7917436, 7922326, 8152638, 8152776, 8152803, 8152804, 8217944, 8422222, 8596633, 8858060, 8880222, 8966982, 8971859, 8972128, 9209729, 9245542, 9256674, 9603028, 9603030, 9603032, 9603035, 9656727, 9680118, 9724035, 10041062, 10041066, 10648067, 11061680, 11562016, 11562019, 12120522, 12168743, 12376820, 12376825, 12681178, 12744603, 13419273, 13536691, 14158330, 14234253]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8dfbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(FEATURES_PREPPED_FILE)\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "df = df.sort_values(by='date')\n",
    "df = df[df['date'] >= START_DATE]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f00b704",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [col for col in df.columns if col not in ['universal_gemrate_id', 'spec_id', 'date', 'price'] and col not in BAD_FEATURES]\n",
    "feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b56c545",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df.iloc[:int(len(df) * TRAIN_TEST_SPLIT)]\n",
    "test_df = df.iloc[int(len(df) * TRAIN_TEST_SPLIT):]\n",
    "val_df = test_df.iloc[:int(len(test_df) * VAL_TEST_SPLIT)]\n",
    "test_df = test_df.iloc[int(len(test_df) * VAL_TEST_SPLIT):]\n",
    "\n",
    "# val_df = val_df.loc[val_df[\"spec_id\"].isin(TOP_100)]\n",
    "# test_df = test_df.loc[test_df[\"spec_id\"].isin(TOP_100)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23025a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df[\"date\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bd70b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df[feature_cols].copy()\n",
    "y_train = train_df['price'].copy()\n",
    "y_train = np.log(train_df['price'].copy())\n",
    "\n",
    "X_val = val_df[feature_cols].copy()\n",
    "y_val = val_df['price'].copy()\n",
    "\n",
    "X_test = test_df[feature_cols].copy()\n",
    "y_test = test_df['price'].copy()\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Validation set: {X_val.shape[0]} samples\")\n",
    "print(f\"Number of features: {len(feature_cols)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b98cb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor(device='cuda')\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [10],\n",
    "    'learning_rate': [0.075],\n",
    "    'n_estimators': [150],\n",
    "    'min_child_weight': [30],\n",
    "    'subsample': [0.9],\n",
    "    'colsample_bytree': [1.0],\n",
    "    'gamma': [0],\n",
    "    'reg_alpha': [0],\n",
    "    'reg_lambda': [5],\n",
    "    'colsample_bylevel': [0.7],\n",
    "    'max_delta_step': [0],\n",
    "}\n",
    "\n",
    "best_score = 99999\n",
    "best_grid = {}\n",
    "for g in ParameterGrid(param_grid):\n",
    "    model.set_params(**g)\n",
    "    model.fit(X_train,y_train)\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    y_val_pred = np.exp(y_val_pred)\n",
    "    mape = mean_absolute_percentage_error(y_val, y_val_pred)\n",
    "    print(f\"MAPE: {mape:.2%}\")\n",
    "    if mape < best_score:\n",
    "        best_score = mape\n",
    "        best_grid = g\n",
    "    print(f\"Best MAPE: {best_score:.2%}\")\n",
    "\n",
    "print (\"Best MAPE: %0.5f\" % best_score )\n",
    "print (\"Best Grid:\", best_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b976ac30",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = XGBRegressor(device='cuda')\n",
    "best_model.set_params(**best_grid)\n",
    "best_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cde3913",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred = best_model.predict(X_val)\n",
    "y_val_pred = np.exp(y_val_pred)\n",
    "\n",
    "val_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "val_mae = mean_absolute_error(y_val, y_val_pred)\n",
    "val_mape = mean_absolute_percentage_error(y_val, y_val_pred)\n",
    "val_r2 = r2_score(y_val, y_val_pred)\n",
    "\n",
    "simple_percent_error = (np.abs(X_val[\"prev_1_price\"].values - y_val.values) / y_val.values) * 100\n",
    "simple_percent_error_series = pd.Series(simple_percent_error, name='simple_percent_error')\n",
    "percent_error = (np.abs(y_val_pred - y_val.values) / y_val.values) * 100\n",
    "percent_error_series = pd.Series(percent_error, name='percent_error')\n",
    "\n",
    "print(\"Validation Metrics:\")\n",
    "print(f\"  RMSE: ${val_rmse:,.2f}\")\n",
    "print(f\"  MAE:  ${val_mae:,.2f}\")\n",
    "print(f\"  MAPE: {val_mape:.2%}\")\n",
    "print(f\"  R²:   {val_r2:.4f}\")\n",
    "\n",
    "print(\"\\nSimple Percent Error Percentiles:\")\n",
    "print(simple_percent_error_series.describe(percentiles=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]))\n",
    "\n",
    "print(\"\\nPercent Error Percentiles:\")\n",
    "print(percent_error_series.describe(percentiles=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dece6ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = best_model.predict(X_test)\n",
    "y_test_pred = np.exp(y_test_pred)\n",
    "\n",
    "val_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "val_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "val_mape = mean_absolute_percentage_error(y_test, y_test_pred)\n",
    "val_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "simple_percent_error = (np.abs(X_test[\"prev_1_price\"].values - y_test.values) / y_test.values) * 100\n",
    "simple_percent_error_series = pd.Series(simple_percent_error, name='simple_percent_error')\n",
    "percent_error = (np.abs(y_test_pred - y_test.values) / y_test.values) * 100\n",
    "percent_error_series = pd.Series(percent_error, name='percent_error')\n",
    "\n",
    "print(\"Test Metrics:\")\n",
    "print(f\"  RMSE: ${val_rmse:,.2f}\")\n",
    "print(f\"  MAE:  ${val_mae:,.2f}\")\n",
    "print(f\"  MAPE: {val_mape:.2%}\")\n",
    "print(f\"  R²:   {val_r2:.4f}\")\n",
    "\n",
    "print(\"\\nSimple Percent Error Percentiles:\")\n",
    "print(simple_percent_error_series.describe(percentiles=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]))\n",
    "\n",
    "print(\"\\nPercent Error Percentiles:\")\n",
    "print(percent_error_series.describe(percentiles=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22652fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': best_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 12))\n",
    "plt.barh(importance_df['feature'][:20], importance_df['importance'][:20])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Top 20 Feature Importances')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "importance_df.head(20)\n",
    "importance_df[\"importance_cumsum\"] = importance_df[\"importance\"].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becf51dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df\n",
    "bad_features = importance_df[importance_df[\"importance_cumsum\"] > 0.95][\"feature\"]\n",
    "list(bad_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
